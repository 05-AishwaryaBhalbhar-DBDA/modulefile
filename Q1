
Mapreduce-
1) Launch the eclipse application using Java perspective
 
2) Click OK for Workspace Launcher
 
3) create a new project :
 
a) File ->New --->Java project
b) Enter "exam" as project name and click Finish
 
4) create a new java program
5) Expand the said project in the Package explorer
6) Right click on Hadoop project --->New --->Class
7) Enter the class name as "StockVolume" and click Finish
8) Enter program in the eclipse and save
import java.io.*;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.fs.*;
import org.apache.hadoop.mapreduce.lib.input.*;
import org.apache.hadoop.mapreduce.lib.output.*;
 
public class StockVolume {
    	
    	public static class MapClass extends Mapper<LongWritable,Text,Text,LongWritable>
    	   {
    	  	public void map(LongWritable key, Text value, Context context)
    	  	{ 		  
    	     	try{
    	        	String[] str = value.toString().split(","); 	
    	        	long vol = Long.parseLong(str[7]);
    	        	context.write(new Text(str[1]),new LongWritable(vol));
    	     	}
    	     	catch(Exception e)
    	     	{
    	        	System.out.println(e.getMessage());
    	     	}
    	  	}
    	   }
    	
    	  public static class ReduceClass extends Reducer<Text,LongWritable,Text,LongWritable>
    	   {
           		private LongWritable result = new LongWritable();
           		
           		public void reduce(Text key, Iterable<LongWritable> values,Context context) throws IOException, InterruptedException {
           	  	long sum = 0;
                          	
           	     	for (LongWritable val : values)
           	     	{         	
           	    	   	sum += val.get();  	
           	     	}
           	     	
           	  	result.set(sum);    	     
           	  	context.write(key, result);
           	  	//context.write(key, new LongWritable(sum));
           	  	
           		}
    	   }
    	  public static void main(String[] args) throws Exception {
           		Configuration conf = new Configuration();
           		//conf.set("name", "value")
           		//conf.set("mapreduce.input.fileinputformat.split.minsize", "134217728");
           		Job job = Job.getInstance(conf, "Volume Count");
           		job.setJarByClass(StockVolume.class);
           		job.setMapperClass(MapClass.class);
           		//job.setCombinerClass(ReduceClass.class);
           		job.setReducerClass(ReduceClass.class);
           		job.setNumReduceTasks(1);
           		job.setOutputKeyClass(Text.class);
           		job.setOutputValueClass(LongWritable.class);
           		FileInputFormat.addInputPath(job, new Path(args[0]));
           		FileOutputFormat.setOutputPath(job, new Path(args[1]));
           		System.exit(job.waitForCompletion(true) ? 0 : 1);
           	  }
}
 
9) add external jar files for the project
a) Right click on Hadoop project --->Build path --->Configure build path
b) select the Libraries tab and click on "Add external jars"
c) click on File System and add 2 jars as under
   	hadoop-common.jar
   	hadoop-mapreduce-client-core.jar
d) After saving the changes there should not be any ERROR in java program
 
10) Create a jar file from class files
a) Right click on Hadoop project --->Export--->Java--->Jar file-->Next
b) enter the jar file name with full path in export destination
jar1.jar
c) click on Finish
 
11) Upload the file jar1.jar and NYSE.csv to client from your base machine.
 
 
 
12)create a training folder
-----------------------
hadoop fs -mkdir exam
 
13)upload NYSE.csv on hdfs
------------------------
hadoop fs -put NYSE.csv exam
 
 
 
 
 
 
 
Run the java jar file on Hadoop for StockVolume
--------------------------------------------------------------------
hadoop jar jar1.jar StockVolume exam/NYSE.csv exam/out1
2nd question-
steps :
----------------------------------------
1) Launch the eclipse application using Java perspective
 
2) Click OK for Workspace Launcher
 
3) create a new project :
 
a) File ->New --->Java project
b) Enter "exam" as project name and click Finish
 
4) create a new java program
5) Expand the said project in the Package explorer
6) Right click on Hadoop project --->New --->Class
7) Enter the class name as "AllTimeHigh" and click Finish
8) Enter program in the eclipse and save
import java.io.*;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.fs.*;
import org.apache.hadoop.mapreduce.lib.input.*;
import org.apache.hadoop.mapreduce.lib.output.*;
 
 
public class AllTimeHigh {
  	
  	public static class MapClass extends Mapper<LongWritable,Text,Text,DoubleWritable>
  	   {
  	  	public void map(LongWritable key, Text value, Context context)
  	  	{ 		    
  	     	try{
  	        	String[] str = value.toString().split(","); 	
  	        	double high = Double.parseDouble(str[4]);
  	        	context.write(new Text(str[1]),new DoubleWritable(high));
  	     	}
  	     	catch(Exception e)
  	     	{
  	        	System.out.println(e.getMessage());
  	     	}
  	  	}
  	   }
  	
  	  public static class ReduceClass extends Reducer<Text,DoubleWritable,Text,DoubleWritable>
  	   {
        		private DoubleWritable result = new DoubleWritable();
        		
        		public void reduce(Text key, Iterable<DoubleWritable> values,Context context) throws IOException, InterruptedException {
        	  	double max = 0.00;
                    	
        	     	for (DoubleWritable val : values)
        	     	{      
        	    		if (val.get() > max) {
        	    	      	max = val.get();
        	    		}
        	     	}
        	     	
        	  	result.set(max);    	     
        	  	context.write(key, result);
        	  	//context.write(key, new LongWritable(sum));
        	  	
        		}
  	   }
  	  public static void main(String[] args) throws Exception {
        		Configuration conf = new Configuration();
        		conf.set("mapreduce.output.textoutputformat.separator",",");
        		//conf.set("name", "value")
        		conf.set("mapreduce.input.fileinputformat.split.maxsize", "28311552");
        		Job job = Job.getInstance(conf, "All Time High Price for each stock");
        		job.setJarByClass(AllTimeHigh.class);
        		job.setMapperClass(MapClass.class);
        		job.setCombinerClass(ReduceClass.class);
        		job.setReducerClass(ReduceClass.class);
        		job.setNumReduceTasks(1);
        		job.setOutputKeyClass(Text.class);
        		job.setOutputValueClass(DoubleWritable.class);
        		FileInputFormat.addInputPath(job, new Path(args[0]));
        		FileOutputFormat.setOutputPath(job, new Path(args[1]));
        		System.exit(job.waitForCompletion(true) ? 0 : 1);
        	  }
}
9) add external jar files for the project
a) Right click on Hadoop project --->Build path --->Configure build path
b) select the Libraries tab and click on "Add external jars"
c) click on File System and add 2 jars as under
   	hadoop-common.jar
   	hadoop-mapreduce-client-core.jar
d) After saving the changes there should not be any ERROR in java program
 
10) Create a jar file from class files
a) Right click on Hadoop project --->Export--->Java--->Jar file-->Next
b) enter the jar file name with full path in export destination
jar1.jar
c) click on Finish
 
11) Upload the file jar2.jar and NYSE.csv to client from your base machine.
 
 
 
12)create a training folder
-----------------------
hadoop fs -mkdir exam
 
13)upload NYSE.csv on hdfs
------------------------
hadoop fs -put NYSE.csv exam
 
 
 
 
 
 
 

2nd question-
steps :
----------------------------------------
1) Launch the eclipse application using Java perspective
 
2) Click OK for Workspace Launcher
 
3) create a new project :
 
a) File ->New --->Java project
b) Enter "exam" as project name and click Finish
 
4) create a new java program
5) Expand the said project in the Package explorer
6) Right click on Hadoop project --->New --->Class
7) Enter the class name as "AllTimeHigh" and click Finish
8) Enter program in the eclipse and save
import java.io.*;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.fs.*;
import org.apache.hadoop.mapreduce.lib.input.*;
import org.apache.hadoop.mapreduce.lib.output.*;
 
 
public class AllTimeHigh {
  	
  	public static class MapClass extends Mapper<LongWritable,Text,Text,DoubleWritable>
  	   {
  	  	public void map(LongWritable key, Text value, Context context)
  	  	{ 		    
  	     	try{
  	        	String[] str = value.toString().split(","); 	
  	        	double high = Double.parseDouble(str[4]);
  	        	context.write(new Text(str[1]),new DoubleWritable(high));
  	     	}
  	     	catch(Exception e)
  	     	{
  	        	System.out.println(e.getMessage());
  	     	}
  	  	}
  	   }
  	
  	  public static class ReduceClass extends Reducer<Text,DoubleWritable,Text,DoubleWritable>
  	   {
        		private DoubleWritable result = new DoubleWritable();
        		
        		public void reduce(Text key, Iterable<DoubleWritable> values,Context context) throws IOException, InterruptedException {
        	  	double max = 0.00;
                    	
        	     	for (DoubleWritable val : values)
        	     	{      
        	    		if (val.get() > max) {
        	    	      	max = val.get();
        	    		}
        	     	}
        	     	
        	  	result.set(max);    	     
        	  	context.write(key, result);
        	  	//context.write(key, new LongWritable(sum));
        	  	
        		}
  	   }
  	  public static void main(String[] args) throws Exception {
        		Configuration conf = new Configuration();
        		conf.set("mapreduce.output.textoutputformat.separator",",");
        		//conf.set("name", "value")
        		conf.set("mapreduce.input.fileinputformat.split.maxsize", "28311552");
        		Job job = Job.getInstance(conf, "All Time High Price for each stock");
        		job.setJarByClass(AllTimeHigh.class);
        		job.setMapperClass(MapClass.class);
        		job.setCombinerClass(ReduceClass.class);
        		job.setReducerClass(ReduceClass.class);
        		job.setNumReduceTasks(1);
        		job.setOutputKeyClass(Text.class);
        		job.setOutputValueClass(DoubleWritable.class);
        		FileInputFormat.addInputPath(job, new Path(args[0]));
        		FileOutputFormat.setOutputPath(job, new Path(args[1]));
        		System.exit(job.waitForCompletion(true) ? 0 : 1);
        	  }
}
9) add external jar files for the project
a) Right click on Hadoop project --->Build path --->Configure build path
b) select the Libraries tab and click on "Add external jars"
c) click on File System and add 2 jars as under
   	hadoop-common.jar
   	hadoop-mapreduce-client-core.jar
d) After saving the changes there should not be any ERROR in java program
 
10) Create a jar file from class files
a) Right click on Hadoop project --->Export--->Java--->Jar file-->Next
b) enter the jar file name with full path in export destination
jar1.jar
c) click on Finish
 
11) Upload the file jar2.jar and NYSE.csv to client from your base machine.
 
 
 
12)create a training folder
-----------------------
hadoop fs -mkdir exam
 
13)upload NYSE.csv on hdfs
------------------------
hadoop fs -put NYSE.csv exam
 
 
 
 
 
 
Run the java jar file on Hadoop for AllTimeHIgh
--------------------------------------------------------------------
hadoop jar jar2.jar AllTimeHIgh exam/NYSE.csv exam/out2
 
